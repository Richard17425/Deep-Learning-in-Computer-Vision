{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "In this portion of the Problem Set, you will gain experience building a CNN for image\n",
    "classification on the MNIST dataset -- a true rite of passage for deep learning and computer\n",
    "vision! Your code should follow this general outline:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download the data. Implement a data loader class to load the dataset. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuba device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#PyTorch - Importing the Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision               #主要用来构建计算机视觉模型\n",
    "import torchvision.transforms    #用来对图像进行变换(裁切，旋转之类)\n",
    "\n",
    "\n",
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./traindata/', train=True, transform=transforms, download=True)  \n",
    "test_dataset = torchvision.datasets.MNIST(root='./testdata/',train=False, transform=transforms, download=True)  \n",
    "device = 'cuba' if torch.cuda.is_available()  else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the Data\n",
    "def imshowPytorch(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # H x W x color_channel\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=False)\n",
    "                                           \n",
    "data_iter = iter(train_loader)\n",
    "images, label = next(data_iter)  # images are 32 x 1 x 28 x 28\n",
    "imshowPytorch(torchvision.utils.make_grid(images[0]))\n",
    "print(label[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the model. We suggest you start with 3 convolutional layers with 24, 48, 64 filters/feature maps, respectively. Each convolutional layer will have 5x5 filters with 2x2 pooling and ReLu activation. Finally, use a fully connected layer to map features to output. (10 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch - Building the Model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_of_class):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.cnn_model = nn.Sequential(\n",
    "            nn.Conv2d(1, 24, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(24, 48, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(48, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_model = nn.Sequential(\n",
    "            nn.Linear(64*3*3,120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = nn.Linear(84, num_of_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_model(x)  # BS x 64 x 5 x 5\n",
    "        x = x.view(-1,64*3*3)  # 64 x 5 x 5 --> 1600 x 1    \n",
    "        x = self.fc_model(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (cnn_model): Sequential(\n",
       "    (0): Conv2d(1, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(24, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (6): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (7): ReLU()\n",
       "    (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (fc_model): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=120, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (classifier): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PyTorch - Visualizing the Model\n",
    "modelpy = NeuralNet(10)\n",
    "modelpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Utilize a gradient-based optimizer. (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(modelpy.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the model! (10 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.27000493106932066\n",
      "Epoch 1: Loss: 0.07612020640416692\n",
      "Epoch 2: Loss: 0.05154861491517125\n",
      "Epoch 3: Loss: 0.03864439514058225\n",
      "Epoch 4: Loss: 0.029694711768523726\n"
     ]
    }
   ],
   "source": [
    "#PyTorch - Training the Model\n",
    "for e in range(5):\n",
    "    # define the loss value after the epoch\n",
    "    losss = 0.0\n",
    "    number_of_sub_epoch = 0\n",
    "    \n",
    "    # loop for every training batch (one epoch)\n",
    "    for images, labels in train_loader:\n",
    "        #create the output from the network\n",
    "        out = modelpy(images)\n",
    "        # count the loss function\n",
    "        loss = criterion(out, labels)\n",
    "        # in pytorch you have assign the zero for gradien in any sub epoch\n",
    "        optim.zero_grad()\n",
    "        # count the backpropagation\n",
    "        loss.backward()\n",
    "        # learning\n",
    "        optim.step()\n",
    "        # add new value to the main loss\n",
    "        losss += loss.item()\n",
    "        number_of_sub_epoch += 1\n",
    "    print(\"Epoch {}: Loss: {}\".format(e, losss / number_of_sub_epoch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate the trained model on an independent test set. What was its performance? What accuracy did your model achieve, and anything in particular that it had trouble with? (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98% with PyTorch\n"
     ]
    }
   ],
   "source": [
    "#PyTorch - Comparing the Results\n",
    "correct = 0\n",
    "total = 0\n",
    "modelpy.eval()  # all of your layers are in eval stage, important for layers such as batchnorm or dropout --> will mess up the result if the network has batchnorm or dropout layers, e.g. RESNET\n",
    "\n",
    "with torch.no_grad(): # all of computation graphs will not update gradients because we will not do any backpropagation --> speed up, doesn't hurt if not called\n",
    "  for images, labels in test_loader:\n",
    "      outputs = modelpy(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)  # outputs.data in shape of BS x 10  -->  BS x 1\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum()\n",
    "print('Test Accuracy of the model on the {} test images: {}% with PyTorch'.format(total, 100 * correct // total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Provide a summary of any architectural modifications made, plots of the loss evolution from (4), and plots of your results from (5). Please save your code and results for submission. (20 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
